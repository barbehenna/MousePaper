{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mouse Population Density Estimation\n",
    "\n",
    "Here I'm playing around with creating a small neural network to take in the results of the simualtions and try to predict the true population density.\n",
    "\n",
    "## Notes\n",
    "\n",
    "I've tried using just the density estimations of each square and it didn't do much better than a linear model (somewhat unsurprisingly). I'm **now incorperating trap spacing and catch radius**. \n",
    "\n",
    "## To-Do\n",
    "\n",
    "- Use some sort of inverse weighting scheme because most of the estimates are already good because the model works well. We need to emphasize the areas where the method doesn't work as well to beat a linear model.\n",
    "- Try adding in other metrics (variance of the error, for instance) and maybe even make it the target for training rather than L2 error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mxnet as mx\n",
    "from mxnet import nd, autograd, gluon\n",
    "from mxboard import SummaryWriter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 3500000\n",
    "epochs = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "num_train_samples = 3500000\n",
    "num_test_samples = 20000\n",
    "\n",
    "context = mx.gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = gluon.nn.Sequential()\n",
    "\n",
    "with net.name_scope():\n",
    "    net.add(gluon.nn.Dense(8, activation=\"relu\"))\n",
    "    net.add(gluon.nn.Dense(8, activation=\"relu\"))\n",
    "    net.add(gluon.nn.Dense(8, activation=\"relu\"))\n",
    "    net.add(gluon.nn.Dense(1))\n",
    "    net.collect_params().initialize(mx.init.Normal(sigma=1.), ctx=context)\n",
    "\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = gluon.nn.Sequential()\n",
    "\n",
    "with net.name_scope():\n",
    "    net.add(gluon.nn.Lambda(lambda x: x.reshape(x.shape[0], 1, x.shape[1])))\n",
    "    net.add(gluon.nn.Conv1D(channels=8, kernel_size=3))\n",
    "    net.add(gluon.nn.Conv1D(channels=8, kernel_size=3))\n",
    "    net.add(gluon.nn.Flatten())\n",
    "    net.add(gluon.nn.Dense(32, activation=\"relu\"))\n",
    "    net.add(gluon.nn.Dense(32, activation=\"relu\"))\n",
    "    net.add(gluon.nn.Dense(32, activation=\"relu\"))\n",
    "    net.add(gluon.nn.Dense(32, activation=\"relu\"))\n",
    "    net.add(gluon.nn.Dense(1))\n",
    "    net.collect_params().initialize(mx.init.Normal(sigma=1.), ctx=context)\n",
    "\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.summary(nd.random.uniform(shape=(batch_size, 8), ctx=context))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simdata = pd.read_csv(\"data/trainingdata-random.csv\")\n",
    "simdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simtrain = simdata.sample(n=num_train_samples)\n",
    "simtest = simdata.drop(simtrain.index).sample(num_test_samples)\n",
    "\n",
    "# predictors = [\"square1\", \"square2\",\"square3\", \"square4\",\"square5\", \"square6\",\"square7\", \"square8\", \"TrapSpacing\", \"CatchRadius\"]\n",
    "predictors = [\"square1\", \"square2\",\"square3\", \"square4\",\"square5\", \"square6\",\"square7\", \"square8\"]\n",
    "\n",
    "Xtrain = nd.array(simtrain[predictors], ctx=context)\n",
    "Ytrain = nd.array(simtrain[\"Density\"], ctx=context)\n",
    "\n",
    "Xtest = nd.array(simtest[predictors], ctx=context)\n",
    "Ytest = nd.array(simtest[\"Density\"], ctx=context)\n",
    "\n",
    "train_data = gluon.data.DataLoader(gluon.data.ArrayDataset(Xtrain, Ytrain), batch_size=batch_size, shuffle=True)\n",
    "test_data = gluon.data.DataLoader(gluon.data.ArrayDataset(Xtest, Ytest), batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_training_batches = np.ceil(Xtrain.shape[0]/batch_size)\n",
    "num_training_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = gluon.Trainer(net.collect_params(), 'adam', {'learning_rate': learning_rate})\n",
    "\n",
    "metric = mx.metric.MSE() # train metric\n",
    "loss = gluon.loss.L2Loss() # L2 loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a summary writer that logs data and flushes to the file every 5 seconds\n",
    "sw = SummaryWriter(logdir='./logs2', flush_secs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(ctx):\n",
    "    metric = mx.metric.MSE()\n",
    "    for data, label in test_data:\n",
    "        data = data.as_in_context(ctx)\n",
    "        label = label.as_in_context(ctx)\n",
    "        output = net(data)\n",
    "        metric.update([label], [output])\n",
    "\n",
    "    return metric.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train the network\n",
    "global_step = 2000\n",
    "for epoch in range(epochs):\n",
    "    epoch += 2000\n",
    "    # reset data iterator and metric at begining of epoch.\n",
    "    metric.reset()\n",
    "    \n",
    "    # training loop for epoch\n",
    "    for i, (data, label) in enumerate(train_data):\n",
    "        # Copy data to context (ctx) if necessary\n",
    "        data = data.as_in_context(context)\n",
    "        label = label.as_in_context(context)\n",
    "        # Start recording computation graph with record() section.\n",
    "        # Recorded graphs can then be differentiated with backward.\n",
    "        with autograd.record():\n",
    "            output = net(data)\n",
    "            L = loss(output, label)\n",
    "        sw.add_scalar(tag='train_loss', value=L.mean().asscalar(), global_step=global_step)\n",
    "        global_step += 1\n",
    "        L.backward()\n",
    "\n",
    "        # take a gradient step with batch_size equal to data.shape[0]\n",
    "        trainer.step(data.shape[0])\n",
    "        \n",
    "        # update metric at last.\n",
    "        metric.update([label], [output])\n",
    "        \n",
    "    # logging training accuracy\n",
    "    name, train_acc = metric.get()\n",
    "    sw.add_scalar(tag='accuracy_curves', value=('train_acc', train_acc), global_step=epoch)\n",
    "    \n",
    "    # logging testing accuracy\n",
    "    name, test_acc = test(context)\n",
    "    sw.add_scalar(tag='accuracy_curves', value=('valid_acc', test_acc), global_step=epoch)\n",
    "        \n",
    "    # Record input and output samples\n",
    "    # sample 10 random inputs and outputs\n",
    "    sampleidx = nd.random_randint(low=0, high=Ytest.shape[0], shape=10, ctx=context)\n",
    "    Xsamples = Xtest[sampleidx]\n",
    "    output_samples = np.array2string(net(Xsamples)[:,0].asnumpy())\n",
    "    expected_ouput = np.array2string(Ytest[sampleidx].asnumpy())\n",
    "#     sw.add_text(tag='output_samples', text=output_samples, global_step=epoch)\n",
    "#     sw.add_text(tag='expected_ouput', text=expected_ouput, global_step=epoch)\n",
    "    if epoch % 10 == 0:\n",
    "        print(\"Output:\", output_samples)\n",
    "        print(\"Expected:\", expected_ouput)\n",
    "    \n",
    "sw.export_scalars('scalar_dict.json')\n",
    "sw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.save_parameters(\"8squaresTSCR-firstmodel-datarand.param\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleidx = nd.random_randint(low=0, high=Ytest.shape[0], shape=10, ctx=context)\n",
    "sampleidx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest[sampleidx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net(Xtest[sampleidx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternate Approach\n",
    "\n",
    "Here I'm fitting the same data but using a random forest rather than a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "simdata = pd.read_csv(\"data/trainingdata-random.csv\")\n",
    "simdata.shape\n",
    "\n",
    "simtrain = simdata.sample(n=100000)\n",
    "simtest = simdata.drop(simtrain.index).sample(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = simtrain[simdata.columns.difference([\"Density\", \"uuid\"])]\n",
    "ytrain = simtrain[\"Density\"]\n",
    "\n",
    "Xtest = simtest[simdata.columns.difference([\"Density\", \"uuid\"])]\n",
    "ytest = simtest[\"Density\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrainrf = Xtrain.asnumpy()\n",
    "ytrainrf = Ytrain.asnumpy()\n",
    "Xtestrf = Xtest.asnumpy()\n",
    "ytestrf = Ytest.asnumpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Xtrain.shape)\n",
    "print(Ytrain.shape)\n",
    "print(Xtest.shape)\n",
    "print(Ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=123, n_jobs=-1)\n",
    "reg = rf.fit(Xtrainrf, ytrainrf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mse = mean_squared_error(ytrainrf, reg.predict(Xtrainrf))\n",
    "test_mse = mean_squared_error(ytestrf, reg.predict(Xtestrf))\n",
    "print(\"train mse:\", train_mse, \"test mse:\", test_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "| Method | Param               | MSE obtained |\n",
    "|--------|---------------------|--------------|\n",
    "| RF     | 100 trees, 20 depth | 0.1297       |\n",
    "| RF     | 100 trees, 10 depth | 0.1516       |\n",
    "| NN     |                     |              |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
