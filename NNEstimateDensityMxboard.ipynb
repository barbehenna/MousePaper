{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mouse Population Density Estimation\n",
    "\n",
    "Here I'm playing around with creating a small neural network to take in the results of the simualtions and try to predict the true population density.\n",
    "\n",
    "## Notes\n",
    "\n",
    "I've tried using just the density estimations of each square and it didn't do much better than a linear model (somewhat unsurprisingly). I'm **now incorperating trap spacing and catch radius**. \n",
    "\n",
    "## To-Do\n",
    "\n",
    "- Use some sort of inverse weighting scheme because most of the estimates are already good because the model works well. We need to emphasize the areas where the method doesn't work as well to beat a linear model.\n",
    "- Try adding in other metrics (variance of the error, for instance) and maybe even make it the target for training rather than L2 error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mxnet as mx\n",
    "from mxnet import nd, autograd, gluon\n",
    "from mxboard import SummaryWriter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10000\n",
    "epochs = 10\n",
    "learning_rate = 0.00001\n",
    "\n",
    "num_train_samples = 80000\n",
    "num_test_samples = 20000\n",
    "\n",
    "context = mx.gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Dense(None -> 8, Activation(relu))\n",
       "  (1): Dense(None -> 8, Activation(relu))\n",
       "  (2): Dense(None -> 8, Activation(relu))\n",
       "  (3): Dense(None -> 1, linear)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = gluon.nn.Sequential()\n",
    "\n",
    "with net.name_scope():\n",
    "    net.add(gluon.nn.Dense(8, activation=\"relu\"))\n",
    "    net.add(gluon.nn.Dense(8, activation=\"relu\"))\n",
    "    net.add(gluon.nn.Dense(8, activation=\"relu\"))\n",
    "    net.add(gluon.nn.Dense(1))\n",
    "    net.collect_params().initialize(mx.init.Normal(sigma=1.), ctx=context)\n",
    "\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14128855, 12)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simdata = pd.read_csv(\"data/trainingdata.csv\")\n",
    "simdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "simtrain = simdata.sample(n=num_train_samples)\n",
    "simtest = simdata.drop(simtrain.index).sample(num_test_samples)\n",
    "\n",
    "predictors = [\"square1\", \"square2\",\"square3\", \"square4\",\"square5\", \"square6\",\"square7\", \"square8\", \"TrapSpacing\", \"CatchRadius\"]\n",
    "\n",
    "Xtrain = nd.array(simtrain[predictors], ctx=context)\n",
    "Ytrain = nd.array(simtrain[\"Density\"], ctx=context)\n",
    "\n",
    "Xtest = nd.array(simtest[predictors], ctx=context)\n",
    "Ytest = nd.array(simtest[\"Density\"], ctx=context)\n",
    "\n",
    "train_data = gluon.data.DataLoader(gluon.data.ArrayDataset(Xtrain, Ytrain), batch_size=batch_size, shuffle=True)\n",
    "test_data = gluon.data.DataLoader(gluon.data.ArrayDataset(Xtest, Ytest), batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_training_batches = np.ceil(Xtrain.shape[0]/batch_size)\n",
    "num_training_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': learning_rate})\n",
    "\n",
    "metric = mx.metric.MSE() # train metric\n",
    "loss = gluon.loss.L2Loss() # L2 loss\n",
    "\n",
    "# define a summary writer that logs data and flushes to the file every 5 seconds\n",
    "sw = SummaryWriter(logdir='./logs', flush_secs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(ctx):\n",
    "    metric = mx.metric.MSE()\n",
    "    for data, label in test_data:\n",
    "        data = data.as_in_context(ctx)\n",
    "        label = label.as_in_context(ctx)\n",
    "        output = net(data)\n",
    "        metric.update([label], [output])\n",
    "\n",
    "    return metric.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Train the network\n",
    "global_step = 0\n",
    "for epoch in range(epochs):\n",
    "    # reset data iterator and metric at begining of epoch.\n",
    "    metric.reset()\n",
    "    \n",
    "    # training loop for epoch\n",
    "    for i, (data, label) in enumerate(train_data):\n",
    "        # Copy data to context (ctx) if necessary\n",
    "        data = data.as_in_context(context)\n",
    "        label = label.as_in_context(context)\n",
    "        # Start recording computation graph with record() section.\n",
    "        # Recorded graphs can then be differentiated with backward.\n",
    "        with autograd.record():\n",
    "            output = net(data)\n",
    "            L = loss(output, label)\n",
    "        sw.add_scalar(tag='train_loss', value=L.mean().asscalar(), global_step=global_step)\n",
    "        global_step += 1\n",
    "        L.backward()\n",
    "\n",
    "        # take a gradient step with batch_size equal to data.shape[0]\n",
    "        trainer.step(data.shape[0])\n",
    "        \n",
    "        # update metric at last.\n",
    "        metric.update([label], [output])\n",
    "        \n",
    "    # logging training accuracy\n",
    "    name, train_acc = metric.get()\n",
    "    sw.add_scalar(tag='accuracy_curves', value=('train_acc', train_acc), global_step=epoch)\n",
    "    \n",
    "    # logging testing accuracy\n",
    "    name, test_acc = test(context)\n",
    "    sw.add_scalar(tag='accuracy_curves', value=('valid_acc', test_acc), global_step=epoch)\n",
    "    \n",
    "    # Record input and output samples\n",
    "    # sample 10 random inputs and outputs\n",
    "    sampleidx = nd.random_randint(low=0, high=Ytest.shape[0], shape=10, ctx=context)\n",
    "    Xsamples = Xtest[sampleidx]\n",
    "    output_samples = np.array2string(net(Xsamples)[:,0].asnumpy())\n",
    "    expected_ouput = np.array2string(Ytest[sampleidx].asnumpy())\n",
    "    sw.add_text(tag='output_samples', text=input_examples, global_step=epoch)\n",
    "    sw.add_text(tag='expected_ouput', text=output_examples, global_step=epoch)\n",
    "    \n",
    "sw.export_scalars('scalar_dict.json')\n",
    "sw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[ 8005  5392 12561 12796 13477 15264 10244 19143  7685  3851]\n",
       "<NDArray 10 @gpu(0)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampleidx = nd.random_randint(low=0, high=Ytest.shape[0], shape=10, ctx=context)\n",
    "sampleidx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 1.4423077   1.6364645   1.4628534   1.4931583   1.5236686   1.5316814\n",
       "   1.4989132   1.8356559   2.6         2.4       ]\n",
       " [ 1.5873016   4.0137744   2.2893903   1.9476081   2.225613    2.189206\n",
       "   1.9913498   1.8782991   2.7         0.6       ]\n",
       " [ 3.9684072   4.412655    4.3017874   4.2950845   4.326702    4.3838844\n",
       "   4.419192    4.571713    3.6         1.2       ]\n",
       " [ 4.6875      4.296875    2.9513888   2.3481889   3.6920455   5.136268\n",
       "   6.704623   10.457072    0.4         1.5       ]\n",
       " [ 2.366864    1.9600592   2.251808    2.431583    2.4142013   2.43261\n",
       "   2.7686574   4.0271297   1.3         2.4       ]\n",
       " [ 2.5080357   2.3742      2.3921778   2.424567    2.4387534   2.4584908\n",
       "   2.4211535   2.4465537   4.          1.3       ]\n",
       " [ 1.171875    0.87890625  1.0416666   1.1474609   1.34375     1.3780382\n",
       "   1.5352471   2.0275555   0.8         0.4       ]\n",
       " [ 2.4722223   2.5833333   2.425926    2.3975694   2.4177778   2.4583333\n",
       "   2.4778912   3.009537    3.          2.8       ]\n",
       " [ 1.4976501   1.4882301   1.5324254   1.5395684   1.4867884   1.4773983\n",
       "   1.4799266   1.605137    2.9         1.2       ]\n",
       " [ 3.3950617   2.3919754   2.3319616   2.9128087   2.851852    2.9837646\n",
       "   3.382896    4.451762    0.9         2.5       ]]\n",
       "<NDArray 10x10 @gpu(0)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest[sampleidx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ -8.623489 ]\n",
       " [ 43.810028 ]\n",
       " [122.97283  ]\n",
       " [ -7.9431996]\n",
       " [ 12.049695 ]\n",
       " [ 41.803925 ]\n",
       " [ 17.071644 ]\n",
       " [ 28.930098 ]\n",
       " [ 12.234928 ]\n",
       " [ 31.174938 ]]\n",
       "<NDArray 10x1 @gpu(0)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(Xtest[sampleidx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
